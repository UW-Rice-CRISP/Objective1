{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Calculating tf-idf stats\n",
    "============="
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.5/site-packages/sklearn/utils/fixes.py:64: DeprecationWarning: inspect.getargspec() is deprecated, use inspect.signature() instead\n",
      "  if 'order' in inspect.getargspec(np.copy)[0]:\n"
     ]
    }
   ],
   "source": [
    "import json\n",
    "import nltk\n",
    "import operator\n",
    "import os\n",
    "\n",
    "from collections import defaultdict\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load vocab..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "vocab_fn = \"vocab.txt\"\n",
    "with open(vocab_fn, \"r+\") as f:\n",
    "    vocab = json.load(f)\n",
    "vocab_set = {x for v in vocab.values() for x in v} # unpacking this a little..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load recorded counts (i.e. the tf parts of tf-idf) and find some interesting files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('water', 579), ('power', 475), ('road', 374), ('port', 255), ('roads', 199)]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "counts_per_file_fn = \"counts_per_file.txt\"\n",
    "with open(counts_per_file_fn, \"r+\") as f:\n",
    "    counts_per_file = json.load(f)\n",
    "\n",
    "counts_agg_fn = \"counts_aggregate.txt\"\n",
    "with open(counts_agg_fn, \"r+\") as f:\n",
    "    counts_agg = json.load(f)\n",
    "\n",
    "sorted(counts_agg.items(), key=lambda x: -x[1])[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('article-96.cfm_nzh.txt', 22),\n",
       " ('article-300.cfm_nzh.txt', 22),\n",
       " ('article-112.cfm_nzh.txt', 17),\n",
       " ('article-163.cfm_nzh.txt', 16),\n",
       " ('article-477.cfm_nzh.txt', 15)]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# most frequent occurrences of the specific word 'water'\n",
    "counts_water = {}\n",
    "for file, vals in counts_per_file.items():\n",
    "    if 'water' in vals and vals['water'] > 0:\n",
    "        counts_water[file] = vals['water']\n",
    "\n",
    "sorted(counts_water.items(), key=lambda x: -x[1])[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load words..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "article_dir = \"../../TextData/CanterburyNewsStoriesCleaned/\"\n",
    "\n",
    "words = {}\n",
    "for article_fn in os.listdir(article_dir):\n",
    "    with open(os.path.join(article_dir, article_fn), \"r+\") as f:\n",
    "        raw = f.read()\n",
    "        \n",
    "    words[article_fn] = raw"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The actual interesting parts!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "tfidf = TfidfVectorizer(stop_words='english')\n",
    "tfs = tfidf.fit_transform(words.values())\n",
    "\n",
    "feature_names = tfidf.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "water  -  0.128132393315\n",
      "truck  -  0.00968514466019\n",
      "traffic  -  0.0470297248563\n",
      "sewers  -  0.0106847034851\n",
      "sewerage  -  0.00991400942576\n",
      "sewer  -  0.0115344954137\n",
      "sewage  -  0.00999620995252\n",
      "sanitation  -  0.011916613096\n",
      "roads  -  0.0203934984642\n",
      "road  -  0.134730017921\n",
      "power  -  0.0761649531149\n",
      "port  -  0.0274129313005\n",
      "fuel  -  0.0437262337802\n",
      "energy  -  0.0077503370286\n",
      "electricity  -  0.00890889869092\n",
      "drinking  -  0.0286361096741\n",
      "distribution  -  0.0104638841988\n",
      "cars  -  0.00876430034165\n",
      "car  -  0.0420513097884\n",
      "bus  -  0.0154436433876\n",
      "airport  -  0.00753239073078\n"
     ]
    }
   ],
   "source": [
    "# looking at a specific doc (one of the ones from above)...\n",
    "response = tfidf.transform([words['article-300.cfm_nzh.txt']])\n",
    "for col in response.nonzero()[1]:\n",
    "    if feature_names[col] in vocab_set:\n",
    "        print (feature_names[col], ' - ', response[0, col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('commutes', 7.2952660014396464),\n",
       " ('petroleum', 7.2952660014396464),\n",
       " ('potable', 7.2952660014396464),\n",
       " ('sanitary', 6.8898008933314818),\n",
       " ('commute', 6.602118820879701),\n",
       " ('electric', 6.602118820879701),\n",
       " ('planes', 6.3789752695654913),\n",
       " ('commuter', 6.1966537127715364),\n",
       " ('utility', 6.1966537127715364),\n",
       " ('airports', 6.0425030329442784)]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# poking around w/inverse document frequency...\n",
    "\n",
    "idf = tfidf.idf_\n",
    "\n",
    "sorted_idf_list = sorted(zip(feature_names, idf), key=lambda x: -x[1])\n",
    "[item for item in sorted_idf_list if item[0] in vocab_set][:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
